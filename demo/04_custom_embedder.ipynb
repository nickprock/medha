{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e02a05f",
   "metadata": {},
   "source": [
    "# Create your Custom Embedder using FastEmbed\n",
    "\n",
    "This notebook shows how to use an embedder that is not listed in FastEmbed but can be used in FastEmbed via Huggingface.\n",
    "\n",
    "In this case, I want to use an embedder for Italian without using a multilingual one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "from medha.interfaces import BaseEmbedder\n",
    "from fastembed import TextEmbedding\n",
    "from fastembed.common.model_description import PoolingType, ModelSource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99594dad",
   "metadata": {},
   "source": [
    "## Create your custom embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastEmbedCustomEmbedder(BaseEmbedder):\n",
    "    \"\"\"\n",
    "    Custom wrapper for FastEmbed that registers a specific model\n",
    "    at initialization and implements the Medha interface.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"nickprock/sentence-bert-base-italian-xxl-uncased\", model_file: str = \"onnx/model_qint8_avx512_vnni.onnx\"):\n",
    "        self._model_name = model_name\n",
    "        self._dim = 768  # Specific size for nickprock/sentence-bert-base-italian-xxl-uncased\n",
    "        self._model_file = model_file # Point to the onnx subfolder\n",
    "\n",
    "        # 1. Registering the custom template in FastEmbed\n",
    "        try:\n",
    "            TextEmbedding.add_custom_model(\n",
    "                model=self._model_name,\n",
    "                pooling=PoolingType.MEAN,\n",
    "                normalization=True,\n",
    "                sources=ModelSource(hf=self._model_name),\n",
    "                dim=self._dim,\n",
    "                model_file= self._model_file \n",
    "            )\n",
    "        except ValueError:\n",
    "            # Handles the case where the model has already been registered\n",
    "            pass\n",
    "\n",
    "        # 2. Initialization of the FastEmbed model\n",
    "        self._model = TextEmbedding(model_name=self._model_name, threads=None)\n",
    "\n",
    "    @property\n",
    "    def dimension(self) -> int:\n",
    "        return self._dim\n",
    "\n",
    "    @property\n",
    "    def model_name(self) -> str:\n",
    "        return self._model_name\n",
    "\n",
    "    async def aembed(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate the embedding for a single string.\n",
    "        \"\"\"\n",
    "        embedding_generator = self._model.embed([text])\n",
    "        return list(next(embedding_generator))\n",
    "\n",
    "    async def aembed_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate the embedding for a list of strings (batch).\n",
    "        \"\"\"\n",
    "        return list(self._model.embed(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c0759",
   "metadata": {},
   "source": [
    "# TEST IT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10012b68",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4591d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Custom Embedder...\")\n",
    "embedder = FastEmbedCustomEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4450a11",
   "metadata": {},
   "source": [
    "## Test one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b610765",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Medha permette di creare pipeline RAG flessibili.\"\n",
    "vector = await embedder.aembed(text)\n",
    "print(f\"\\nSingle embedding completed.\")\n",
    "print(f\"Dimension: {len(vector)} (Expected: 768)\")\n",
    "print(f\"First 5 values: {vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76edce",
   "metadata": {},
   "source": [
    "## Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc29b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "        \"L'integrazione di modelli custom è semplice.\",\n",
    "        \"FastEmbed usa ONNX runtime per la velocità.\"\n",
    "    ]\n",
    "batch_vectors = await embedder.aembed_batch(texts)\n",
    "print(f\"\\nBatch embedding completed for {len(batch_vectors)} sentences.\")\n",
    "print(f\"Dimensions of the first vector: {len(batch_vectors[0])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
